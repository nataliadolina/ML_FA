{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swITvb0pzwpu"
      },
      "source": [
        "<h1 align='center'> Нейронные сети в PyTorch для классификации изображений "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fY3vHCKszwpx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTh62eGyzwpy"
      },
      "source": [
        "## Данные MNIST\n",
        "\n",
        "Воспользуемся встроенным в PyTorch набором изображений рукописных цифр с разрешением 28x28."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ux4wHzGhzwpz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2705331b-963b-402e-f052-a503a08f6cd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 109347898.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 80918967.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 24722303.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 18406307.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESyTOfFWzwp1"
      },
      "source": [
        "Индексация и визуализация набора данных\n",
        "---\n",
        "\n",
        "Мы можем индексировать наборы данных вручную, как список: `training_data[index]`. Мы используем `matplotlib` для визуализации некоторых выборок в наших обучающих данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "9ushjWKXzwp1",
        "outputId": "3604012f-215c-4a23-9b19-2b4063e851fc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(label)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzlJoLOaZJtp"
      },
      "source": [
        "## Coздание загрузчика данных средствами Fastai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastbook"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNF19Ca8zWMF",
        "outputId": "7004ce4a-0f2f-404a-b288-ce7c6689fad1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fastbook\n",
            "  Downloading fastbook-0.0.29-py3-none-any.whl (719 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastai>=2.6 in /usr/local/lib/python3.9/dist-packages (from fastbook) (2.7.12)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.9/dist-packages (from fastbook) (0.20.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from fastbook) (23.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from fastbook) (2.27.1)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipywidgets<8 in /usr/local/lib/python3.9/dist-packages (from fastbook) (7.7.1)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (from fastbook) (23.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from fastbook) (1.4.4)\n",
            "Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.9/dist-packages (from fastai>=2.6->fastbook) (8.4.0)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.9/dist-packages (from fastai>=2.6->fastbook) (3.5.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from fastai>=2.6->fastbook) (6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from fastai>=2.6->fastbook) (1.10.1)\n",
            "Requirement already satisfied: torch<2.1,>=1.7 in /usr/local/lib/python3.9/dist-packages (from fastai>=2.6->fastbook) (2.0.0+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from fastai>=2.6->fastbook) (1.2.2)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.9/dist-packages (from fastai>=2.6->fastbook) (0.15.1+cu118)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /usr/local/lib/python3.9/dist-packages (from fastai>=2.6->fastbook) (1.5.29)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.9/dist-packages (from fastai>=2.6->fastbook) (1.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from fastai>=2.6->fastbook) (3.7.1)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.9/dist-packages (from fastai>=2.6->fastbook) (0.0.7)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets<8->fastbook) (7.34.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.9/dist-packages (from ipywidgets<8->fastbook) (5.5.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets<8->fastbook) (3.0.7)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets<8->fastbook) (3.6.4)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.9/dist-packages (from ipywidgets<8->fastbook) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets<8->fastbook) (0.2.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets->fastbook) (1.22.4)\n",
            "Collecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets->fastbook) (9.0.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting huggingface-hub<1.0.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets->fastbook) (4.65.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets->fastbook) (2023.3.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->fastbook) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->fastbook) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->fastbook) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->fastbook) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->fastbook) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->fastbook) (2022.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers->fastbook) (3.10.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers->fastbook) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->fastbook) (22.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets->fastbook) (4.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.9/dist-packages (from ipykernel>=4.5.1->ipywidgets<8->fastbook) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipykernel>=4.5.1->ipywidgets<8->fastbook) (6.2)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets<8->fastbook) (3.0.38)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets<8->fastbook) (0.7.5)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets<8->fastbook) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets<8->fastbook) (2.14.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets<8->fastbook) (0.1.6)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets<8->fastbook) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets<8->fastbook) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets<8->fastbook) (67.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->fastbook) (1.16.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai>=2.6->fastbook) (3.1.2)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai>=2.6->fastbook) (0.7.0)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai>=2.6->fastbook) (1.1.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai>=2.6->fastbook) (1.10.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai>=2.6->fastbook) (1.0.9)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai>=2.6->fastbook) (3.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai>=2.6->fastbook) (2.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai>=2.6->fastbook) (2.0.7)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai>=2.6->fastbook) (8.1.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai>=2.6->fastbook) (3.0.12)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai>=2.6->fastbook) (2.4.6)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai>=2.6->fastbook) (6.3.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai>=2.6->fastbook) (0.10.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai>=2.6->fastbook) (3.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<4->fastai>=2.6->fastbook) (1.0.4)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch<2.1,>=1.7->fastai>=2.6->fastbook) (2.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch<2.1,>=1.7->fastai>=2.6->fastbook) (3.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch<2.1,>=1.7->fastai>=2.6->fastbook) (1.11.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch<2.1,>=1.7->fastai>=2.6->fastbook) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch<2.1,>=1.7->fastai>=2.6->fastbook) (3.25.2)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.9/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (6.4.8)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->fastai>=2.6->fastbook) (4.39.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->fastai>=2.6->fastbook) (1.0.7)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->fastai>=2.6->fastbook) (5.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->fastai>=2.6->fastbook) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->fastai>=2.6->fastbook) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->fastai>=2.6->fastbook) (1.4.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->fastai>=2.6->fastbook) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->fastai>=2.6->fastbook) (3.1.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->fastai>=2.6->fastbook) (3.15.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets<8->fastbook) (0.8.3)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (5.3.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (21.3.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (0.16.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (1.5.6)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (6.5.4)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (0.17.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (5.8.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (23.2.1)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (1.8.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<8->fastbook) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets<8->fastbook) (0.2.6)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai>=2.6->fastbook) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai>=2.6->fastbook) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<4->fastai>=2.6->fastbook) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<4->fastai>=2.6->fastbook) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch<2.1,>=1.7->fastai>=2.6->fastbook) (1.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (3.2.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.9/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (21.2.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (1.2.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (4.11.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (0.7.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (0.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (4.9.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (1.5.0)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (0.2.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (6.0.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.9/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (2.16.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (0.19.3)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (2.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8->fastbook) (2.21)\n",
            "Installing collected packages: tokenizers, sentencepiece, xxhash, multidict, jedi, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets, fastbook\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.11.0 dill-0.3.6 fastbook-0.0.29 frozenlist-1.3.3 huggingface-hub-0.13.4 jedi-0.18.2 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 sentencepiece-0.1.97 tokenizers-0.13.3 transformers-4.27.4 xxhash-3.2.0 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8SLUoNvZJtp",
        "outputId": "988ab5a7-4389-4ae8-e242-c4c5d42fa2bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "from fastbook import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrOvPpBdZJtp"
      },
      "source": [
        "Функции загрузки, проверки и очистки изображений\n",
        "----\n",
        "Давайте воспользуемся загрузкой файлов из интернета при помощи функции `download_url()`, и откроем при помощи `Image.open()`. В визуализации нам поможет функция `to_thumb()` из модуля `fastai.vision`.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "Zi2FqRaUZJtq",
        "outputId": "105bc430-3d6a-4d42-fdce-c009389b2a02"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='8192' class='' max='4808' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      170.38% [8192/4808 00:00&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=P size=300x267>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAELBAMAAACR+qbIAAAAD1BMVEXm5ub///8AAABYWFikpKR2nnpoAAAFK0lEQVR4nO3cAXKbMBAFUENyAKA9AJJ9gDjpAWzf/1ANdjCSkAzoL9pVRsxUM22w+0bS/zSY9NC2zeEgbhBAKKzfyjocqrYVOAggFNbvZPGnLqeC4CcUFswSkLqMCkICobDAgT91ORUEP6GwYJaA1GVUEBIIhQUO/KnLqSD4CYUFswSkLqOCkEAoLHDgT11OBcFPKCyYJSB1SQri+5dEVq2VQFattT7LY92+WbqB34o4Q9Wg0kdpBdHdWVoY6+2h0kdRrFaPhyhW92T1IIu0SZ+q7+6SUxA3kax6UumTHJY2DzGsGyWLLIm1pdJCCsJeQjGsTiTrr6M6ymA5Kq1AFk0S3SWUUaeNq9Lwm1KwPl3VhwTWbAkb/E0JWK4K36vyKousIGi7gYrlTJai6EH6JiWpZ/wd3MmiYcGhsTurJ+lBvCCcazSFiIJlr+FVCsvZWEJY9mS1ZCwsNM5kUYSQoiCcyZLCstqBprIoWM7OEsLq7MkiZEF52adJ0YJ4tydLCstaQzoRytqp4EGWNVmEomEA8nIzVOitZbqCsL7hUWJY9T7XHZS103WHkkUoerCi82KuoSLtBqggPkWyrBzSihCWtYZyWDteDochNi+G6kQaQqggzOthL4dl5pBWhLCsDS+HZa7heQ9WXFTMHJJ3Q3xBWBteDMtcw0Yk60Qvimbte5UehpiomHcAG+oQxheEsYZHclE8y6j4XhDLyqEYllkP9KIHKyIlxhqqPbohsiCMybrKYb0ZLKNn3r++rpwsY2upx58Z3zL2DRfL2FqXyv3M50kFh+0pMQhzlL7fvOEoiDnEOQgqdvtL6kXW8ExZcla3zMJv4Gx/iWc3eVzJW36NSvfJC2IVK/mjP3/WsVI/stitZCmZLPCe19aUrFXpPmlBrGZBnbr1JSuDOBznhKy1QdRY1W99SZeItTEldZjx79JW1iInLAj/bJ3a6ZTpjCYd6+ZB9YEJ7dOxPFtoNimf41f4WNdXF4J0Le/OlO+853ds6QrCUgUKs+ZlqcB56VnmJVGFztPJWea1Z/lC0Kdq+XpSqeXGDZ5CXRAT62NFh5yTsz7WTGibnBU+ZVpD6AEXYpZ5zx5gbUvJcyqCpxiT5b8G7FEQyywtklWzsvrQKYYKeRwokqUCp9RUrLgkqsAppkrFdkN8QQRYpgr8WJawt24Wq0nHGlfp6PtqZ6leXAh2Y/kW0VGFtt8eLT/+69STxDdblfaOTZA1uznRMLCOwfofD+zT4q0vGf965ws3VwV+lEHCmv0koIZ/UnhjSsaNfQl1+8+R+mf2n2s0lcZ8BbF/xgOs6eaV//4gIophjZvrYv/WOfDPOiNZ929rnP/VYDoalLU1JW6Z+ycLCGFUQXjLYK5Kzlr+TJjicaDtL+kWWQ0Ha3EVQVFUy1eLnxjQPAex/SX1axUuimO9XEVFIIpjvdr0ikIUyQpPlyIRxbT8MISmq6IIYWRBDINfRSMCWL7pOjXsLM/uOlOJANY8jGcyUWzL+6q+IaoFpCDuQ231AqkIYRnbqyUWIaxD9fMc+JVchLF2HQjjw18QhSVpEEDwsgSkLqOCkEAoLHDgT11OBcFPKCyYJSB1GRWEBEJhgQN/6nIqCH5CYcEsAanLqCAkEAoLHPhTl1NB8BMKC2YJSF1GBSGBUFjgwJ+6nAqCn1BYMEtA6jIqCAmEwgIH/tTlVBD8hMKCWQJSl1FBSCAUFjjwpy6nguAnFBbMEpC6jApCAqGwwIE/dTkVBD+hsGCWgNTlUxD/Aa+CVN6mjXH9AAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "link=['https://e7.pngegg.com/pngimages/173/894/png-clipart-logo-brand-number-design-white-text.png']\n",
        "dest = 'images/six.jpg'\n",
        "download_url(link[0], dest)\n",
        "im = Image.open(dest)\n",
        "im.to_thumb(300,300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQx74Vz8ZJtq"
      },
      "source": [
        "Теперь используем URL, не содержащий изображения, и попробуем сохранить его как изображение в туже папку под именем six1.jpg. Для получения списка путей к файлам в папке с изображениями можно использовать функцию `get_image_files()` модуля `fastai.data.transform`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "ZDLTK1T-ZJtq",
        "outputId": "f4ba6d04-7a88-4603-db1f-069f85dc7f9d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='172032' class='' max='164369' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      104.66% [172032/164369 00:00&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('images/six1.jpg'),Path('images/six.jpg')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "link1=['https://habr.com/ru/company/wunderfund/blog/314242/']\n",
        "dest1 = 'images/six1.jpg'\n",
        "download_url(link1[0], dest1)\n",
        "img = get_image_files('images')\n",
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsi_nK_dZJtr"
      },
      "source": [
        "Очевидно, файл six1.jpg не является изображением, проверить это можно при помощи функции `verify_image()` из модуля `fastai.vision.utils`. Функция выведет список ошибочных файлов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11mCS22GZJtr",
        "outputId": "cd9d057b-e294-45c2-a44b-61fa434118cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#1) [Path('images/six1.jpg')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "failed = verify_images(img)\n",
        "failed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hghe1zl-ZJtr"
      },
      "source": [
        "Чтобы удалить все неудачные изображения, вы можете использовать разорвать связь на каждом из них. Обратите внимание, что, как и большинство функций fastai, возвращающих коллекцию, `verify_images()` возвращает объект типа `L`, который включает метод `map`. Этот метод вызывает переданную функцию для каждого элемента коллекции:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBmbMcGlZJts",
        "outputId": "82772edc-5e84-4f2e-b46b-8d8f8e82af3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#1) [Path('images/six.jpg')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "failed.map(Path.unlink)\n",
        "img = get_image_files('images')\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "UoIKMAbhZJts",
        "outputId": "9ca48a36-3988-4dc7-e0c9-fbbbb1eb6844"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.03% [15687680/15683414 00:00&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#60000) [Path('/root/.fastai/data/mnist_png/training/4/22105.png'),Path('/root/.fastai/data/mnist_png/training/4/20251.png'),Path('/root/.fastai/data/mnist_png/training/4/14496.png'),Path('/root/.fastai/data/mnist_png/training/4/26855.png'),Path('/root/.fastai/data/mnist_png/training/4/50069.png'),Path('/root/.fastai/data/mnist_png/training/4/3183.png'),Path('/root/.fastai/data/mnist_png/training/4/30702.png'),Path('/root/.fastai/data/mnist_png/training/4/58613.png'),Path('/root/.fastai/data/mnist_png/training/4/11144.png'),Path('/root/.fastai/data/mnist_png/training/4/3417.png')...]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "path = untar_data(URLs.MNIST)/'training'\n",
        "num_img=get_image_files(path)\n",
        "num_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsKASzn3ZJts",
        "outputId": "3a66005f-a088-4dc1-c5fb-f6ae7e62890d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#0) []"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "failed = verify_images(num_img)\n",
        "failed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1b4WLXhZJtt"
      },
      "source": [
        "Загрузчики данных\n",
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpjFp-0uZJtt"
      },
      "source": [
        "Далее вы также узнаете о fastai классах `Dataset` и `Datasets`, которые имеют одинаковые отношения.\n",
        "\n",
        "Чтобы превратить наши загруженные данные в объект `Dataloader`, нам нужно определить как минимум четыре вещи:\n",
        "\n",
        "- С какими видами данных мы работаем\n",
        "- Как получить список элементов\n",
        "- Как пометить эти элементы\n",
        "- Как создать поверочный набор\n",
        "\n",
        "До сих пор мы видели ряд методов `fastai` для определенных комбинаций этих вещей, которые удобны, когда у вас есть приложение и структура данных, которые случайно вписываются в эти предопределенные методы. Для тех случаев, когда вы этого не делаете, `fastai` имеет чрезвычайно гибкую систему, называемую API блоков данных. С помощью этого API вы можете полностью настроить каждый этап создания ваших загрузчиков данных. Вот что нам нужно, чтобы создать загрузчики данных для набора данных, который мы только что загрузили:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OjErMkehZJtt"
      },
      "outputs": [],
      "source": [
        "mnist = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock), \n",
        "    get_items=get_image_files, \n",
        "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
        "    get_y=parent_label,\n",
        "    item_tfms=Resize(28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmE1RWywZJtt"
      },
      "source": [
        "Давайте рассмотрим каждый из этих аргументов по очереди. Сначала мы предоставляем кортеж, в котором мы указываем, какие типы мы хотим для независимых и зависимых переменных:\n",
        "\n",
        "```python\n",
        "blocks=(ImageBlock, CategoryBlock)\n",
        "```\n",
        "\n",
        "*Независимая переменная* - это то, что мы используем для составления прогнозов, а *зависимая переменная* - наша цель. В этом случае нашими независимыми переменными являются изображения, а нашими зависимыми переменными являются категории (тип цифры) для каждого изображения. \n",
        "\n",
        "Для этих `DataLoaders` нашими базовыми элементами будут пути к файлам. Необходимо указать `DataBlock`, как получить список этих файлов. Функция `get_image_files()` принимает путь и возвращает список всех изображений в этом пути (рекурсивно, по умолчанию):\n",
        "\n",
        "```python\n",
        "get_items=get_image_files()\n",
        "```\n",
        "\n",
        "Часто загружаемые наборы данных уже имеют набор данных проверки. Иногда это делается путем размещения изображений для обучающих и проверочных наборов в разные папки. Иногда это делается путем предоставления CSV-файла, в котором указано каждое имя файла вместе с набором данных, в котором оно должно находиться. Есть много способов, которыми это можно сделать, и `fastai` предоставляет очень общий подход, который позволяет вам использовать для этого один из своих предопределенных классов или написать свой собственный. В этом случае, однако, мы просто хотим разделить наши обучающие и проверочные наборы случайным образом. Тем не менее, мы хотели бы иметь одинаковое разделение обучения/проверки при каждом запуске этой записной книжки, поэтому мы исправляем случайное начальное число(если вы каждый раз предоставляете одну и ту же отправную точку для этого списка, называемую *seed*, то каждый раз вы будете получать один и тот же список):\n",
        "\n",
        "\n",
        "```python\n",
        "splitter=RandomSplitter(valid_pct=0.2, seed=42)\n",
        "```\n",
        "Независимую переменную часто называют `x`, а зависимую переменную часто называют `y`. Здесь мы сообщаем fastai, какую функцию вызывать для создания меток в нашем наборе данных:\n",
        "\n",
        "```python\n",
        "get_y=parent_label\n",
        "```\n",
        "\n",
        "`parent_label` - это функция, предоставляемая fastai, которая просто находит имя папки, в которой находится файл. Поскольку мы помещаем каждое из наших изображений цифр в папки в зависимости от цифры, это даст нам нужные метки.\n",
        "\n",
        "Изображения могут быть разного размера, и это проблема для глубокого обучения: мы подаем модели не по одному изображению за раз, а несколько из них (то, что мы называем *мини-пакетом*). Чтобы сгруппировать их в большой массив (обычно называемый *тензором*), который будет проходить через нашу модель, все они должны быть одинакового размера. Итак, можно добавить преобразование, которое изменит размер этих изображений до того же размера. *Преобразования элементов* - это фрагменты кода, которые выполняются для каждого отдельного элемента, будь то изображение, категория или так далее. fastai включает в себя множество предопределенных преобразований; здесь можно использовать преобразование изменяющее размер  `Resize`:\n",
        "\n",
        "```python\n",
        "item_tfms=Resize(28)\n",
        "```\n",
        "\n",
        "Но поскольку набор данных MNIST содержит изображения одинакового разрешения нам это не понадобится. Команда дала нам объект `DataBlock`. Это похоже на *шаблон* для создания `DataLoaders`. Нам все еще нужно сообщить fastai фактический источник наших данных — в данном случае путь, по которому можно найти изображения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "21oQE0hgZJtu"
      },
      "outputs": [],
      "source": [
        "dls = mnist.dataloaders(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Yp8-ka8ZJtu"
      },
      "source": [
        "`DataLoaders` включают в себя загрузчики данных для проверки и обучения. `DataLoaders` - это класс, который предоставляет графическому процессору пакеты из нескольких элементов одновременно. Когда вы просматриваете загрузчик данных, `fastai` будет выдавать вам 64 (по умолчанию) элемента за раз, все они собраны в один тензор. Мы можем взглянуть на некоторые из этих элементов, вызвав метод `show_batch` в `DataLoaders`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "Emoa6X80ZJtu",
        "outputId": "8e1e2aa1-7e36-4f38-e240-6fa90c9654c6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x300 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "dls.valid.show_batch(max_n=4, nrows=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5CJb55ozwp3"
      },
      "source": [
        "## Вернемся к тензорам\n",
        "\n",
        "Сначала давайте создадим модель, не используя ничего, кроме тензорных операций Pytorch. PyTorch предоставляет методы для создания случайных или заполненных нулем тензоров, которые мы будем\n",
        "использовать для создания наших весов и смещения для простой линейной модели. Это просто обычные тензоры, с одним очень специальным дополнением: мы говорим PyTorch, что им требуется\n",
        "градиент. Это заставляет PyTorch записывать все операции, выполняемые с тензором, чтобы он мог автоматически вычислять градиент во время обратного распространения.\n",
        "<div class=\"alert alert-info\"><h4>Примечание:</h4><p>Мы инициализируем веса, используя\n",
        "   <a href='http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf'>инициализацию Xavier Glorot</a> (умножая на 1/sqrt(n)).</p></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mVlBqMcHzwp4"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "weights = torch.randn(28*28, 10) / math.sqrt(28*28)\n",
        "weights.requires_grad_()\n",
        "bias = torch.zeros(10, requires_grad=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeXDXWstzwp5"
      },
      "source": [
        "Благодаря способности PyTorch автоматически вычислять градиенты, мы можем использовать любую стандартную функцию Python (или вызываемый объект) в качестве модели! Итак, давайте просто напишем простое матричное умножение и broadcast сложение, чтобы создать простую линейную модель. Нам также нужна функция активации, поэтому мы напишем `log_softmax` и будем ее использовать. Помните: хотя PyTorch предоставляет множество предварительно написанных функций потери, функций активации и т. д., Вы можете легко написать свои собственные, используя обычный python. PyTorch даже автоматически создаст быстрый GPU или векторизованный GPU код для вашей функции."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "eW7uq82-zwp6"
      },
      "outputs": [],
      "source": [
        "def log_softmax(x):\n",
        "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
        "\n",
        "def model(xb):\n",
        "    return log_softmax(xb @ weights + bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOXUXk3Bzwp6"
      },
      "source": [
        "В приведенном выше примере `@` означает операцию `.dot`. Мы вызовем нашу функцию на одном пакете данных (в данном случае 64 изображения). Это один проход вперед. Обратите внимание, что на данном этапе наши прогнозы будут не лучше случайных, так как мы начинаем со случайных весов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUS5dLBXzwp7",
        "outputId": "e91c337c-ea5e-478f-d02b-6218b92ffdb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-2.0200, -2.2622, -2.7712, -2.5609, -2.4867, -2.3719, -2.5162, -2.2697, -2.2454, -1.8520], grad_fn=<SelectBackward0>) torch.Size([64, 10])\n",
            "tensor([5., 0., 4., 1., 9., 2., 1., 3., 1., 4., 3., 5., 3., 6., 1., 7., 2., 8., 6., 9., 4., 0., 9., 1., 1., 2., 4., 3., 2., 7., 3., 8., 6., 9., 0., 5., 6., 0., 7., 6., 1., 8., 7., 9., 3., 9., 8., 5.,\n",
            "        9., 3., 3., 0., 7., 4., 9., 8., 0., 9., 4., 1., 4., 4., 6., 0.])\n"
          ]
        }
      ],
      "source": [
        "bs = 64  # размер пакета\n",
        "xb=torch.zeros(bs,28*28)\n",
        "yb=torch.zeros(bs)\n",
        "for i in range(bs):\n",
        "    img_b,target_b = training_data[i]# мини-пакет из x\n",
        "    xb[i,:]=img_b.view(1,-1)\n",
        "    yb[i]=target_b\n",
        "\n",
        "preds = model(xb)  # предсказания\n",
        "preds[0], preds.shape\n",
        "print(preds[0], preds.shape)\n",
        "print(yb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr-FfQjHzwp8"
      },
      "source": [
        "Тензор `preds` содержит не только значения тензора, но и функцию градиента. Мы воспользуемся этим позже, чтобы сделать обратное распространение ошибки.\n",
        "\n",
        "Давайте перекодируем целевую переменную, так чтобы ее можно было сравнивать с предсказанием модели, используем кодирование One-hot. Проверим его для значения 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQxc2_ckzwp9",
        "outputId": "107a95fb-cdea-480f-f7e7-171a55d087da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).\n",
        "                        scatter_(0, y.type(torch.int64), value=1))\n",
        "target_transform(torch.tensor(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-yAli2Qzwp-"
      },
      "source": [
        "Поскольку `taget_transform` преобразует тензор-число в тензор-вектор, для пакета целевых переменных необходимо сформировать тензор-матрицу размера 10x64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4noBXnY3zwp-",
        "outputId": "2a05475d-c5c2-4beb-e5ba-78f932262fd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]),\n",
              " torch.Size([64, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "target_b=torch.vstack([target_transform(t) for t in yb])\n",
        "target_b[:5,:], target_b.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2ynS5HZzwp_"
      },
      "source": [
        "Давайте реализуем отрицательную логарифмическую вероятность для использования в качестве функции потерь (опять же, мы можем просто использовать стандартный Python):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jFQ7tIqbzwp_"
      },
      "outputs": [],
      "source": [
        "def nll(input, target):\n",
        "    return (-input*target).mean()\n",
        "\n",
        "loss_func = nll"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn_9vZUcZJty"
      },
      "source": [
        "Посмотрим подробнее как работает функция nll()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQYAao2FZJty",
        "outputId": "cc4ba2e5-5adf-4975-c236-95124b5b8586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000], dtype=torch.float64)\n",
            "tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "inp_vec=torch.tensor(np.arange(0,1,0.1))\n",
        "tag=target_transform(torch.tensor(5))\n",
        "print(inp_vec[range(tag.shape[0])]*tag)\n",
        "print(inp_vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzJgz9L4ZJty"
      },
      "source": [
        "Задание 1.\n",
        "---\n",
        "Обратите внимание, что сумма компонент вектора `inp_vec` не равна 1, в этом смысле он не может быть сформирован в модели логистической регрессии. Какую функцию необходимо использовать для того, чтобы преобразовать компоненты к виду вектора вероятности? Преобразуйте этот вектор к вектору вероятности. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_vec = torch.div(inp_vec, torch.sum(inp_vec))\n",
        "\n",
        "print(inp_vec)\n",
        "print(inp_vec.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vVmGo7YZZXG",
        "outputId": "57e4b28e-2c22-41c6-9080-30e946370b1d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0000, 0.0222, 0.0444, 0.0667, 0.0889, 0.1111, 0.1333, 0.1556, 0.1778, 0.2000], dtype=torch.float64)\n",
            "tensor(1., dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMc1BQ-Uzwp_"
      },
      "source": [
        "Давайте проверим ошибку нашей случайной модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKgLWBsdzwqA",
        "outputId": "af1f9ee2-98eb-439b-f6e3-ff8c9d61513a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2306, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(loss_func(preds, target_b))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrObgOWX3KI6"
      },
      "source": [
        "Реализуем функцию для расчета точности нашей модели. Для каждого прогноза, если индекс с наибольшим значением соответствует целевому значению, то прогноз был правильным."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "i3DcT_FlzwqB"
      },
      "outputs": [],
      "source": [
        "def accuracy(out, yb):\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    return (preds == yb).float().mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGbN9gqi4Pe7"
      },
      "source": [
        "Давайте проверим точность нашей случайной модели, чтобы увидеть, улучшается ли наша точность по мере увеличения потерь."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rss7CT7M4BFm",
        "outputId": "7277367c-cb32-4538-cf11-78eb344d844e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1094)\n"
          ]
        }
      ],
      "source": [
        "print(accuracy(preds, yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQYdBuH55Qip"
      },
      "source": [
        "Теперь мы можем запустить цикл обучения. Для каждой итерации мы будем:\n",
        "\n",
        "- выберать мини-пакет данных (размером `bs`)\n",
        "- использовать модель для составления прогнозов\n",
        "- рассчитывать потери\n",
        "- `loss.backward()` обновляет градиенты модели, в данном случае `weights`\n",
        "и `bias`.\n",
        "\n",
        "Теперь мы используем эти градиенты для обновления весов и смещения. Мы делаем это в контекстном менеджере `torch.no_grad ()`, потому что мы не хотим, чтобы эти действия были записаны для нашего следующего вычисления градиента. Вы можете прочитать\n",
        "больше о том, как Autograd PyTorch записывает операции <a href='https://pytorch.org/docs/stable/notes/autograd.html'>здесь </a>.\n",
        "\n",
        "Затем мы устанавливаем градиенты равными нулю, чтобы быть готовыми к следующему циклу. В противном случае наши градиенты записали бы текущий подсчет всех выполненных операций (т. е. `loss.backward()` *добавляет* градиенты ко всему, что уже сохранено, а не заменяет их).\n",
        "\n",
        ".. Совет:: Вы можете использовать стандартный отладчик python для пошагового выполнения PyTorch код, позволяющий проверять различные значения переменных на каждом шаге. Раскомментируйте `set_trace()` ниже, чтобы попробовать."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "97EOge4o7k63"
      },
      "outputs": [],
      "source": [
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "lr = 0.5  # скорость обучения\n",
        "epochs = 2  # количество эпох\n",
        "bs = 64 # количество данных в пакете\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i in range((training_data.__len__() - 1) // bs + 1):\n",
        "        #set_trace()\n",
        "        start_i = i * bs\n",
        "        end_i = start_i + bs\n",
        "        if end_i>training_data.__len__() - 1: bs=training_data.__len__() - 1-start_i\n",
        "        xbs=torch.zeros(bs,28*28)\n",
        "        ybs=torch.zeros(bs)\n",
        "        for j in range(bs):\n",
        "          img_bs,tar_bs = training_data[start_i+j]# мини-пакет из x\n",
        "          xbs[j,:]=img_bs.flatten()\n",
        "          ybs[j]=tar_bs\n",
        "          if j==0:\n",
        "              target_bs=target_transform(ybs[j])#one-hot кодирование\n",
        "          else:\n",
        "              target_bs=torch.vstack([target_bs,target_transform(ybs[j])])\n",
        "        pred = model(xbs)\n",
        "        loss = loss_func(pred, target_bs)\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            weights -= weights.grad * lr\n",
        "            bias -= bias.grad * lr\n",
        "            weights.grad.zero_()\n",
        "            bias.grad.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPNrb7IGuzop"
      },
      "source": [
        "Вот и все: мы создали и обучили минимальную нейронную сеть (в данном случае\n",
        "логистическую регрессию, поскольку у нас нет скрытых слоев) полностью с нуля!\n",
        "\n",
        "Давайте проверим потери и точность и сравним их с тем, что мы получили\n",
        "ранее. Мы ожидаем, что потери уменьшатся, а точность\n",
        "увеличится, и они это сделали."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7E01gx_nDPt",
        "outputId": "84f5ec5c-ea4d-48dd-dba4-5559a29a2160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0271, grad_fn=<MeanBackward0>) tensor(0.9375)\n"
          ]
        }
      ],
      "source": [
        "print(loss_func(model(xb), target_b), accuracy(model(xb), yb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWqU6-4Jz8k2"
      },
      "source": [
        "## Использование функции torch.nn.\n",
        "\n",
        "Теперь проведем рефакторинг нашего кода, чтобы он делал то же самое, что и раньше, только начнем использовать преимущества классов PyTorch `nn`, чтобы сделать его более кратким и гибким. На каждом последующем шаге мы должны делать наш код одним или несколькими из следующих: более коротким, понятным и/или более гибким.\n",
        "\n",
        "Первый и самый простой шаг-сделать наш код короче, заменив наши\n",
        "написанные от руки функции активации и потери на функции из `torch.nn.functional`(который обычно импортируется в пространство имен `F` по соглашению). Этот модуль содержит все функции в библиотеке `torch.nn` (в то время как другие части библиотеки содержат классы). Помимо широкого спектра функций потери и активации, вы также найдете здесь некоторые удобные функции для создания нейронных сетей, такие как функции объединения. (Существуют также функции для выполнения сверток, линейных слоев и т. д., Но, как мы увидим, они обычно лучше обрабатываются с помощью других частей библиотеки.)\n",
        "\n",
        "Если вы используете функцию потери как отрицательную вероятность подобия `nll` и активацию `softmax`, то Pytorch предоставляет единую функцию `F.cross_entropy`, которая объединяет эти две. Таким образом, мы даже можем удалить функцию активации из нашей модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ga3sbRN4xYli"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "loss_func = F.cross_entropy\n",
        "\n",
        "def model(xb):\n",
        "    return xb @ weights + bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb_Yi7pu4QAn"
      },
      "source": [
        "Обратите внимание, что мы больше не вызываем `log_softmax` в функции модели. Давайте подтвердим, что наши потери и точность такие же, как и раньше. Необходимо лишь преобразовать тип к `long`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3NwT4qC4f2v",
        "outputId": "9aca6b30-b71b-4e92-e059-1fde28436bc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2710, grad_fn=<NllLossBackward0>) tensor(0.9375)\n"
          ]
        }
      ],
      "source": [
        "print(loss_func(model(xb), yb.type(torch.long)), accuracy(model(xb), yb.type(torch.long)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "077HOjEE6Ytt"
      },
      "source": [
        "## Рефакторинг с использованием nn.Module\n",
        "\n",
        "В следующий раз мы будем использовать `nn.Module` и `nn.Parameter`, для более четкого и краткого цикла обучения. Мы подкласс `nn.Module` (который сам по себе является классом и способен отслеживать состояние).  В этом случае мы хотим создать класс, который будет содержать наши веса, смещение и метод для шага вперед.  `nn.Module` имеет ряд атрибутов и методов (таких как `.parameters()` и `.zero_grade()`) которые мы будем использовать.\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Примечание:</h4><p>`nn.Module` (прописная буква M) - это специфическая концепция PyTorch, и это\n",
        "класс, который мы будем часто использовать. `nn.Module` не следует путать с концепцией Python <a href=https://docs.python.org/3/tutorial/modules.html> модуля</a> (в нижнем регистре m), который представляет собой файл кода Python, который можно импортировать.</p></div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "3uReAZoG4p0Z"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class Mnist_Logistic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
        "        self.bias = nn.Parameter(torch.zeros(10))\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return xb @ self.weights + self.bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_sbLT7NCtIP"
      },
      "source": [
        "Поскольку теперь мы используем класс, а не просто функцию, сначала нам нужно создать экземпляр нашей модели. Теперь мы можем рассчитать потери так же, как и раньше. Обратите внимание, что объекты `nn.Module` используются так, как если бы они были функциями (т. е. они вызываемы), но за кулисами Pytorch автоматически вызовет наш метод переадресации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJqBwTt0CS2d",
        "outputId": "26a27fb4-f219-43b0-9c53-ab898867a4c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3812, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model = Mnist_Logistic()\n",
        "print(loss_func(model(xb), yb.type(torch.long)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSCHQydvEiIE"
      },
      "source": [
        "Ранее для нашего цикла обучения нам приходилось обновлять значения для каждого параметра по имени и вручную обнулять оценки для каждого параметра отдельно, например: \n",
        "```python            \n",
        "         with torch.no_grad():\n",
        "            weights -= weights.grad * lr\n",
        "            bias -= bias.grad * lr\n",
        "            weights.grad.zero_()\n",
        "            bias.grad.zero_()\n",
        "```\n",
        "Теперь мы можем воспользоваться преимуществами `model.parameters()` и `model.zero_grad()` (которые оба определены PyTorch для `nn.Module`), чтобы сделать эти шаги более краткими и менее подверженными ошибке забывания некоторых наших параметров, особенно если бы у нас была более сложная модель: \n",
        "```python\n",
        "  with torch.no_grad()\n",
        "      for p in model.parameters(): \n",
        "        p -= p.grad * lr \n",
        "      model.zero_grad()\n",
        "```\n",
        "\n",
        "Мы завернем наш небольшой тренировочный цикл в функцию подгонки, чтобы позже запустить его снова."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "jsSK2AfyFZYy"
      },
      "outputs": [],
      "source": [
        "def fit(train_data, model, loss_func, lr=0.5, epochs=2, bs=64,):\n",
        "    for epoch in range(epochs):\n",
        "        for i in range((train_data.__len__() - 1) // bs + 1):\n",
        "           #set_trace()\n",
        "            start_i = i * bs\n",
        "            end_i = start_i + bs\n",
        "            if end_i>train_data.__len__() - 1: bs=train_data.__len__() - 1-start_i\n",
        "            xbs=torch.zeros(bs,28*28)\n",
        "            ybs=torch.zeros(bs)\n",
        "            for j in range(bs):\n",
        "                img_bs,tar_bs = train_data[start_i+j]# мини-пакет из x\n",
        "                xbs[j,:]=img_bs.view(1,-1)\n",
        "                ybs[j]=tar_bs\n",
        "            pred = model(xbs)\n",
        "            loss = loss_func(pred, ybs.type(torch.long))\n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for p in model.parameters():\n",
        "                    p -= p.grad * lr\n",
        "                model.zero_grad()\n",
        "\n",
        "fit(training_data, model, loss_func)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFGRTxDdKodv"
      },
      "source": [
        "Оценим точность:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFYKtjXGKuOP",
        "outputId": "0fb4e22c-5716-4196-8795-60b8338be8ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1521, grad_fn=<NllLossBackward0>) tensor(0.9688)\n"
          ]
        }
      ],
      "source": [
        "print(loss_func(model(xb), yb.type(torch.long)), accuracy(model(xb), yb.type(torch.long)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oe_gAtJLnSc"
      },
      "source": [
        "Рефакторинг с использованием nn.Linear\n",
        "-------------------------\n",
        "\n",
        "Мы продолжаем рефакторинг нашего кода. Вместо того, чтобы вручную определять и\n",
        "инициализировать `self.weights` и `self.bias`, а также вычислять `xb @ self.weights + self.bias`, вместо этого мы будем использовать класс PyTorch[`nn.Linear`](https://pytorch.org/docs/stable/nn.html#linear-layers)  для\n",
        "линейного слоя, который делает все это за нас. В Pytorch есть много типов\n",
        "предопределенных слоев, которые могут значительно упростить наш код и часто делают его быстрее."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "4-rDSnRUK5Cp"
      },
      "outputs": [],
      "source": [
        "class Mnist_Logistic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lin = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return self.lin(xb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCq3RQP_NoqR"
      },
      "source": [
        "Мы создаем экземпляр нашей модели и рассчитываем потери так же, как и раньше:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl-J-w_7NVtB",
        "outputId": "faf59c56-6ed5-451d-ce15-1e401b722ebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2954, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model = Mnist_Logistic()\n",
        "print(loss_func(model(xb), yb.type(torch.long)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBgr46vxN-_0"
      },
      "source": [
        "Обучим модель определим точность предсказаний:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHrvo7N1N25L",
        "outputId": "4b36b87d-843c-4b04-e5a4-d38d30b360ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1558, grad_fn=<NllLossBackward0>) tensor(0.9531)\n"
          ]
        }
      ],
      "source": [
        "fit(training_data, model, loss_func)\n",
        "print(loss_func(model(xb), yb.type(torch.long)), accuracy(model(xb), yb.type(torch.long)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dSlfPGpPXLs"
      },
      "source": [
        "## Рефакторинг с использованием optim\n",
        "\n",
        "У PyTorch также есть пакет с различными алгоритмами оптимизации `torch.optim`.\n",
        "Мы можем использовать метод `step` от нашего оптимизатора, чтобы сделать шаг вперед, вместо того, чтобы вручную обновлять каждый параметр.\n",
        "\n",
        "Это позволит нам заменить наш предыдущий шаг оптимизации, закодированный вручную:\n",
        "``` python \n",
        "    with torch.no_grad():\n",
        "        for p in model.parameters():\n",
        "            p -= p.grad * lr\n",
        "            model.zero_grad()\n",
        "```\n",
        "\n",
        "и вместо этого используйте просто:\n",
        "``` python\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "```\n",
        "\n",
        "(`optim.zero_grand()` сбрасывает градиент до 0, и нам нужно вызвать его до\n",
        "вычисление градиента для следующего мини-пакета.)\n",
        "Мы определим небольшую функцию для создания нашей модели и оптимизатора, чтобы мы могли повторно использовать ее в будущем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW4CpgTGOb-3",
        "outputId": "812bb28c-0dcb-4066-a1ae-319586be4ccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.3802, grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1640, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "from torch import optim\n",
        "\n",
        "def get_model(lr=0.5):\n",
        "    model = Mnist_Logistic()\n",
        "    return model, optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "model, opt = get_model(0.1)\n",
        "print(loss_func(model(xb), yb.type(torch.long)))\n",
        "\n",
        "def fit(train_data, model, loss_func, epochs=2, bs=64):\n",
        "  for epoch in range(epochs):\n",
        "    for i in range((train_data.__len__() - 1) // bs + 1):\n",
        "        #set_trace()\n",
        "        bs1=bs\n",
        "        start_i = i * bs\n",
        "        end_i = start_i + bs\n",
        "        if end_i>train_data.__len__() - 1: bs=train_data.__len__() - 1-start_i\n",
        "        xbs=torch.zeros(bs,28*28)\n",
        "        ybs=torch.zeros(bs)\n",
        "        for j in range(bs):\n",
        "          img_bs,tar_bs = train_data[start_i+j]# мини-пакет из x\n",
        "          xbs[j,:]=img_bs.view(1,-1)\n",
        "          ybs[j]=tar_bs\n",
        "        bs=bs1\n",
        "        pred = model(xbs)\n",
        "        loss = loss_func(pred, ybs.type(torch.long))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "fit(training_data, model, loss_func, 10)\n",
        "print(loss_func(model(xb), yb.type(torch.long)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrO5cXa2GQbe"
      },
      "source": [
        "## Задание1\n",
        "\n",
        "Провести рефакторинг кода, используя DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "nEu8c1i63hnL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "mnist_models = {}\n",
        "\n",
        "class Mnist_Logistic(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lin = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return self.lin(xb.view(-1, 784))\n",
        "\n",
        "def fit(train_dl, model, loss_func, optimizer, epochs=5):\n",
        "        for epoch in range(epochs):\n",
        "            for xb, yb in train_dl:\n",
        "                pred = model(xb)\n",
        "                loss = loss_func(pred, yb)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "-AtSYda27Ozp"
      },
      "outputs": [],
      "source": [
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor())\n",
        "\n",
        "train_dl = DataLoader(training_data, batch_size=32, shuffle=True)\n",
        "\n",
        "model = Mnist_Logistic()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLPCFOtqGO_I",
        "outputId": "27ba2597-61fc-40f7-b79a-c293d9e6b300"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time for Mnist_Logistic: 396.8508336544037\n",
            "tensor(0.1114, grad_fn=<NllLossBackward0>) tensor(0.9844)\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "fit(train_dl, model, loss_func, optimizer, 40)\n",
        "end_time = time.time()\n",
        "\n",
        "execution_time = end_time - start_time\n",
        "print(\"Execution time for Mnist_Logistic:\", execution_time)\n",
        "\n",
        "_loss_func = loss_func(model(xb), yb.type(torch.long))\n",
        "_accuracy = accuracy(model(xb), yb.type(torch.long))\n",
        "print(_loss_func, _accuracy)\n",
        "\n",
        "mnist_models[\"Mnist_Logistic\"] = {\"execution time\": execution_time, \"loss\": _loss_func, \"accuracy\": _accuracy}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTIs-yEbQLeG"
      },
      "source": [
        "## Переключитесь на CNN\n",
        "\n",
        "Теперь мы собираемся построить нашу нейронную сеть с тремя сверточными слоями.\n",
        "Поскольку ни одна из функций в предыдущем разделе ничего не предполагает о\n",
        "форме модели, мы сможем использовать их для обучения CNN без каких-либо изменений.\n",
        "\n",
        "Мы будем использовать предопределенные Pytorch\n",
        "<a href=https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d> Conv2d </a> класс как наш сверточный слой. Мы определяем CNN с 3 сверточными слоями.\n",
        "За каждой сверткой следует ReLU.  В конце мы выполняем\n",
        "среднее объединение."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n"
      ],
      "metadata": {
        "id": "JCawZBXOscH8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "J_7gU50FQ9Ep"
      },
      "outputs": [],
      "source": [
        "class Mnist_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        xb = xb.view(-1, 1, 28, 28)\n",
        "        xb = F.relu(self.conv1(xb))\n",
        "        xb = F.relu(self.conv2(xb))\n",
        "        xb = F.relu(self.conv3(xb))\n",
        "        xb = F.avg_pool2d(xb, 4)\n",
        "        return xb.view(-1, xb.size(1))\n",
        "\n",
        "lr = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xXeV-LeRLps"
      },
      "source": [
        "## Задание2\n",
        "\n",
        "Провести обучение модели Mnist-CNN. Сравнить точность и скорость обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FykILC4NRKjX"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(train_dl, model, loss_func, optimizer, epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        for xb, yb in train_dl:\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n"
      ],
      "metadata": {
        "id": "ywE0Ovaibkeu"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor())\n",
        "\n",
        "train_dl = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "\n",
        "model = Mnist_CNN()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "nWgGAX56bwaV"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "fit(train_dl, model, loss_func, optimizer, 40)\n",
        "end_time = time.time()\n",
        "\n",
        "execution_time = end_time - start_time\n",
        "print(\"Execution time for Mnist_CNN:\", execution_time)\n",
        "\n",
        "_loss_func = loss_func(model(xb), yb.type(torch.long))\n",
        "_accuracy = accuracy(model(xb), yb.type(torch.long))\n",
        "print(_loss_func, _accuracy)\n",
        "\n",
        "mnist_models[\"Mnist_CNN\"] = {\"execution time\": execution_time, \"loss\": _loss_func, \"accuracy\": _accuracy}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6EIU8MhsO9c",
        "outputId": "146eec96-6ea1-4819-9d6d-2b9b446f014d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time for Mnist_CNN: 539.9750940799713\n",
            "tensor(0.0591, grad_fn=<NllLossBackward0>) tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4reSRxKMsP_0",
        "outputId": "4f26b032-1de5-4fac-a9c1-a19d69b59a86"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Mnist_Logistic': {'execution time': 396.8508336544037,\n",
              "  'loss': tensor(0.1114, grad_fn=<NllLossBackward0>),\n",
              "  'accuracy': tensor(0.9844)},\n",
              " 'Mnist_CNN': {'execution time': 539.9750940799713,\n",
              "  'loss': tensor(0.0591, grad_fn=<NllLossBackward0>),\n",
              "  'accuracy': tensor(1.)}}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}